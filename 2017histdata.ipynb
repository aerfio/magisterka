{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using plaidml.keras.backend backend.\n"
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense \n",
    "from keras.optimizers import Adam\n",
    "# from keras.callbacks import TensorBoard\n",
    "import time\n",
    "# PLOT=True\n",
    "PLOT=False\n",
    "\n",
    "SEQ_LEN=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        open     high      low    close\ndate                                                   \n2017-01-02 02:00:00  1.05155  1.05197  1.05155  1.05190\n2017-01-02 02:01:00  1.05209  1.05209  1.05177  1.05179\n2017-01-02 02:02:00  1.05177  1.05198  1.05177  1.05178\n2017-01-02 02:03:00  1.05188  1.05200  1.05188  1.05200\n2017-01-02 02:04:00  1.05196  1.05204  1.05196  1.05203",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-02 02:00:00</th>\n      <td>1.05155</td>\n      <td>1.05197</td>\n      <td>1.05155</td>\n      <td>1.05190</td>\n    </tr>\n    <tr>\n      <th>2017-01-02 02:01:00</th>\n      <td>1.05209</td>\n      <td>1.05209</td>\n      <td>1.05177</td>\n      <td>1.05179</td>\n    </tr>\n    <tr>\n      <th>2017-01-02 02:02:00</th>\n      <td>1.05177</td>\n      <td>1.05198</td>\n      <td>1.05177</td>\n      <td>1.05178</td>\n    </tr>\n    <tr>\n      <th>2017-01-02 02:03:00</th>\n      <td>1.05188</td>\n      <td>1.05200</td>\n      <td>1.05188</td>\n      <td>1.05200</td>\n    </tr>\n    <tr>\n      <th>2017-01-02 02:04:00</th>\n      <td>1.05196</td>\n      <td>1.05204</td>\n      <td>1.05196</td>\n      <td>1.05203</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "url = \"./datasets/DAT_ASCII_EURUSD_M1_2017.csv\"\n",
    "df = pd.read_csv(url, names=list([\"date\",\"open\", \"high\", \"low\", \"close\", \"volume\"]), header=None, sep=\";\")\n",
    "df.drop(\"volume\", 1, inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    df.plot(subplots=True, layout=(2, 2), figsize=(40, 20), sharex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.05155]\n [1.05177]\n [1.05177]\n ...\n [1.19961]\n [1.19974]\n [1.1998 ]]\n"
    }
   ],
   "source": [
    "data_set = df.iloc[:, 2:3].values #close\n",
    "print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(371635, 1)\n"
    }
   ],
   "source": [
    "print(data_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.05155]\n [1.05177]\n [1.05177]\n ...\n [1.19961]\n [1.19974]\n [1.1998 ]]\n"
    }
   ],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(data_set)\n",
    "print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.10006866 0.10132738 0.10132738 0.10195675 0.10241446 0.10241446\n 0.1029294  0.10315826 0.10310104 0.10304383 0.10327269 0.10338712\n 0.10315826 0.10298661 0.10321547 0.10310104 0.10327269 0.10132738\n 0.10127017 0.10104131 0.10109852 0.10127017 0.10167067 0.10127017\n 0.10167067 0.1013846  0.10149903 0.10132738 0.10155624 0.10132738\n 0.1017851  0.10212839 0.10252889 0.10264332 0.10275775 0.10264332\n 0.10161346 0.10189953 0.10115574 0.10075524 0.10075524 0.10069802\n 0.10086966 0.10092688 0.10041195 0.10069802 0.10058359 0.0998398\n 0.09966815 0.09989701 0.0994393  0.09955372 0.09852386 0.09875272\n 0.098295   0.0986955  0.09858107 0.09978258 0.09955372 0.09995423]\n"
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(SEQ_LEN, training_set_scaled.size-1):\n",
    "    X_train.append(training_set_scaled[i-SEQ_LEN:i, 0])\n",
    "    y_train.append(training_set_scaled[i+1, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.10006866]\n [0.10132738]\n [0.10132738]\n [0.10195675]\n [0.10241446]\n [0.10241446]\n [0.1029294 ]\n [0.10315826]\n [0.10310104]\n [0.10304383]\n [0.10327269]\n [0.10338712]\n [0.10315826]\n [0.10298661]\n [0.10321547]\n [0.10310104]\n [0.10327269]\n [0.10132738]\n [0.10127017]\n [0.10104131]\n [0.10109852]\n [0.10127017]\n [0.10167067]\n [0.10127017]\n [0.10167067]\n [0.1013846 ]\n [0.10149903]\n [0.10132738]\n [0.10155624]\n [0.10132738]\n [0.1017851 ]\n [0.10212839]\n [0.10252889]\n [0.10264332]\n [0.10275775]\n [0.10264332]\n [0.10161346]\n [0.10189953]\n [0.10115574]\n [0.10075524]\n [0.10075524]\n [0.10069802]\n [0.10086966]\n [0.10092688]\n [0.10041195]\n [0.10069802]\n [0.10058359]\n [0.0998398 ]\n [0.09966815]\n [0.09989701]\n [0.0994393 ]\n [0.09955372]\n [0.09852386]\n [0.09875272]\n [0.098295  ]\n [0.0986955 ]\n [0.09858107]\n [0.09978258]\n [0.09955372]\n [0.09995423]]\n"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "opt = Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "NAME = f\"PRED-{int(time.time())}\"  \n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "model.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=32,validation_data=[X_test, y_test])\n",
    "\n",
    "model.save('histdata.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenv07056f12f87c4c6fa7d060979708382c",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}